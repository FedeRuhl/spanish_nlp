{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish NLP: Spell Checking Notebook\n",
    "\n",
    "This notebook demonstrates how to use the `SpanishSpellChecker` class from the `spanish_nlp` library.\n",
    "\n",
    "It supports multiple spell checking methods:\n",
    "*   `dictionary`: Uses `pyspellchecker` based on dictionary lookups and edit distance.\n",
    "*   `contextual_lm`: Uses a transformer-based masked language model (like BETO) for context-aware corrections.\n",
    "\n",
    "For more information visit [spanish_nlp](https://github.com/jorgeortizfuentes/spanish_nlp) repository on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary class and configure logging to see informational messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from spanish_nlp import SpanishSpellChecker\n",
    "\n",
    "# Configure logging to see messages from the library\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# You might want to set a higher level (e.g., logging.WARNING) for less verbose output\n",
    "# logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Dictionary-Based Spell Checker (`method='dictionary'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize with default settings (language='es', distance=2)\n",
    "    dict_checker = SpanishSpellChecker(method='dictionary')\n",
    "    print(f\"Initialized: {dict_checker.get_implementation_details()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing dictionary checker: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_simple = \"Ola kmo stás? Esto es un testo de prueva.\"\n",
    "\n",
    "if 'dict_checker' in locals():\n",
    "    print(f\"Original Text: {text_simple}\")\n",
    "    \n",
    "    # Find potential errors\n",
    "    errors = dict_checker.find_errors(text_simple)\n",
    "    print(f\"Potential Errors: {errors}\")\n",
    "    \n",
    "    # Check a specific word\n",
    "    print(f\"Is 'stás' correct? {dict_checker.is_correct('stás')}\")\n",
    "    print(f\"Is 'hola' correct? {dict_checker.is_correct('hola')}\")\n",
    "    \n",
    "    # Get suggestions for a word\n",
    "    suggestions = dict_checker.suggest('pruevs')\n",
    "    print(f\"Suggestions for 'pruevs': {suggestions}\")\n",
    "    \n",
    "    # Get the single best correction for a word\n",
    "    correction = dict_checker.correct_word('testo')\n",
    "    print(f\"Correction for 'testo': {correction}\")\n",
    "    \n",
    "    # Correct the entire text (use with caution)\n",
    "    corrected_text = dict_checker.correct_text(text_simple)\n",
    "    print(f\"Corrected Text: {corrected_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Dictionary and Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Example with distance 1 and adding custom words\n",
    "    custom_words = ['nlp', 'pythonista']\n",
    "    dict_checker_custom = SpanishSpellChecker(method='dictionary', \n",
    "                                            distance=1, \n",
    "                                            custom_dictionary=custom_words)\n",
    "    \n",
    "    text_custom = \"Me gusta el nlp y soy un buen pythonista.\"\n",
    "    print(f\"\\nOriginal Text: {text_custom}\")\n",
    "    errors_custom = dict_checker_custom.find_errors(text_custom)\n",
    "    print(f\"Potential Errors (custom dict): {errors_custom}\") # Should be empty\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing custom dictionary checker: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Contextual Language Model (`method='contextual_lm'`)\n",
    "\n",
    "This method uses a transformer model (like BETO) to understand context. It's generally better for distinguishing between correctly spelled words used incorrectly (e.g., homophones) but is computationally more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize using BETO model, auto-detect device (GPU if available)\n",
    "    # You can specify device='cpu' or device=0 (for first GPU)\n",
    "    lm_checker = SpanishSpellChecker(\n",
    "        method='contextual_lm',\n",
    "        model_name=\"dccuchile/bert-base-spanish-wwm-uncased\", # BETO\n",
    "        top_k=5, # Number of candidates model considers internally\n",
    "        suggestion_distance_threshold=2 # Filter suggestions by Levenshtein distance\n",
    "    )\n",
    "    print(f\"Initialized: {lm_checker.get_implementation_details()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing contextual checker: {e}\")\n",
    "    print(\"Make sure 'transformers', 'torch' (or 'tensorflow'), 'accelerate', and 'python-Levenshtein' are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_context_1 = \"Fui ha ver la pelicula.\"\n",
    "text_context_2 = \"El tubo se rompio.\"\n",
    "text_context_3 = \"No ce si ir al cine.\"\n",
    "\n",
    "if 'lm_checker' in locals():\n",
    "    print(f\"Original 1: {text_context_1}\")\n",
    "    # is_correct only checks vocabulary, 'ha' might be in vocab\n",
    "    print(f\"Is 'ha' in vocab? {lm_checker.is_correct('ha')}\") \n",
    "    # correct_text uses context\n",
    "    corrected_1 = lm_checker.correct_text(text_context_1)\n",
    "    print(f\"Corrected 1: {corrected_1}\")\n",
    "    \n",
    "    print(f\"\\nOriginal 2: {text_context_2}\")\n",
    "    corrected_2 = lm_checker.correct_text(text_context_2)\n",
    "    print(f\"Corrected 2: {corrected_2}\") # Model might choose 'tubo' or 'tuvo'\n",
    "    \n",
    "    print(f\"\\nOriginal 3: {text_context_3}\")\n",
    "    corrected_3 = lm_checker.correct_text(text_context_3)\n",
    "    print(f\"Corrected 3: {corrected_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Suggestions (Less Reliable without Context)\n",
    "\n",
    "The `suggest` and `correct_word` methods for the contextual checker work by masking the word in isolation. They lack context and are less reliable than `correct_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lm_checker' in locals():\n",
    "    word_isolated = \"vien\"\n",
    "    suggestions_isolated = lm_checker.suggest(word_isolated)\n",
    "    correction_isolated = lm_checker.correct_word(word_isolated)\n",
    "    \n",
    "    print(f\"\\nSuggestions for '{word_isolated}' (isolated): {suggestions_isolated}\")\n",
    "    print(f\"Correction for '{word_isolated}' (isolated): {correction_isolated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spanish_nlp import classifiers\n",
    "\n",
    "sc = classifiers.SpanishClassifier(model_name=\"hate_speech\", device=\"cpu\")\n",
    "t1 = \"LAS MUJERES Y GAYS DEBERÍAN SER EXTERMINADOS\"\n",
    "t2 = (\n",
    "    \"El presidente convocó a una reunión a los representantes de los partidos políticos\"\n",
    ")\n",
    "p1 = sc.predict(t1)\n",
    "p2 = sc.predict(t2)\n",
    "\n",
    "print(\"Text 1: \", t1)\n",
    "print(\"Prediction 1: \", p1)\n",
    "print(\"Text 2: \", t2)\n",
    "print(\"Prediction 2: \", p2)\n",
    "\n",
    "\n",
    "# Install package pip in this folder pip (forcing): pip install\n",
    "# --force-reinstall -e .\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from spanish_nlp.classifiers import SpanishClassifier\n",
    "from spanish_nlp.preprocess import SpanishPreprocess\n",
    "\n",
    "# Load Spanish DataFrame with tweets\n",
    "df = pd.read_csv(\n",
    "    \"tweets.csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8\",\n",
    "    quotechar='\"',\n",
    "    dtype={\"id\": object, \"user_id\": object},\n",
    ")\n",
    "\n",
    "sp = SpanishPreprocess(\n",
    "    lower=True,\n",
    "    remove_url=True,\n",
    "    remove_hashtags=True,\n",
    "    preserve_emojis=True,\n",
    "    preserve_emoticons=True,\n",
    "    convert_emoticons=False,\n",
    "    convert_emojis=False,\n",
    "    normalize_inclusive_language=False,\n",
    "    reduce_spam=True,\n",
    "    remove_vowels_accents=True,\n",
    "    remove_punctuation=True,\n",
    "    remove_unprintable=True,\n",
    "    remove_numbers=True,\n",
    "    remove_stopwords=False,\n",
    "    stopwords_list=None,\n",
    "    stem=False,\n",
    ")\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].swifter.apply(sp.transform)\n",
    "\n",
    "df = df[df.text.notnull()]\n",
    "df = df[df.text != \"\"]\n",
    "df = df[df[\"text\"].apply(lambda x: isinstance(x, str))]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def predict_label(text, model, file_log):\n",
    "    try:\n",
    "        return model.predict(text)\n",
    "    except Exception as e:\n",
    "        time = datetime.now().strftime(\"%d-%Y-%m %H:%M:%S\")\n",
    "        # Write log\n",
    "        with open(file_log, \"a\") as f:\n",
    "            f.write(f\"{time}. Error: {e}\\n\")\n",
    "            f.write(f\"{model}. Model: {model}\\n\")\n",
    "            f.write(f\"{time}. Text: {text}\\n\")\n",
    "        return None\n",
    "\n",
    "\n",
    "classifiers_names = [\n",
    "    \"hate_speech\",\n",
    "    \"toxic_speech\",\n",
    "    \"sentiment_analysis\",\n",
    "    \"emotion_analysis\",\n",
    "    \"irony_analysis\",\n",
    "    \"sexist_analysis\",\n",
    "    \"racism_analysis\",\n",
    "]\n",
    "classifiers = {}\n",
    "\n",
    "file_log = \"classification.log\"\n",
    "\n",
    "classifiers_names = [\n",
    "    \"hate_speech\",\n",
    "    \"toxic_speech\",\n",
    "    \"sentiment_analysis\",\n",
    "    \"emotion_analysis\",\n",
    "    \"irony_analysis\",\n",
    "    \"sexist_analysis\",\n",
    "    \"racism_analysis\",\n",
    "]\n",
    "classifiers = {}\n",
    "\n",
    "for n in classifiers_names:\n",
    "    classifiers[n] = SpanishClassifier(model_name=n, device=0)\n",
    "\n",
    "for cl_name in classifiers.keys():\n",
    "    df[cl_name] = None\n",
    "    df[cl_name] = df[\"text\"].swifter.apply(\n",
    "        lambda x: predict_label(x, classifiers[cl_name], file_log)\n",
    "    )\n",
    "    df.to_pickle(\"tweets_classified.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55f6ada9710d2be3261dfe6106fc8a8d32ccc4c77b66e487f6b103b7c5a66cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
